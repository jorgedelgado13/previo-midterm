[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PRACTICAS",
    "section": "",
    "text": "Code\n%pip install matplotlib seaborn scikit-learn pandas numpy\n\n\nRequirement already satisfied: matplotlib in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (3.10.6)\nRequirement already satisfied: seaborn in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (1.7.2)\nRequirement already satisfied: pandas in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (2.3.2)\nRequirement already satisfied: numpy in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (2.2.6)\nRequirement already satisfied: contourpy&gt;=1.0.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler&gt;=0.10 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (4.60.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging&gt;=20.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow&gt;=8 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: python-dateutil&gt;=2.7 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy&gt;=1.8.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (1.16.2)\nRequirement already satisfied: joblib&gt;=1.2.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pytz&gt;=2020.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport seaborn as sns\n\n\n\n\n\n\n\nCode\nfrom sklearn.datasets import make_classification\n\n# Generar dataset ficticio\nX, y = make_classification(n_samples=1000, n_features=5, \n                           n_informative=3, n_redundant=0, \n                           random_state=42)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, \n                                                    random_state=42)\n\n\n\n\n\n\nCode\n# Crear el modelo\nmodelo = LogisticRegression()\n\n# Entrenar con los datos\nmodelo.fit(X_train, y_train)\n\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n100\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\n\n\nCode\n# Predicción de clases\ny_pred = modelo.predict(X_test)\n\n# Predicción de probabilidades\ny_prob = modelo.predict_proba(X_test)[:,1]  # prob. de clase positiva\n\n\n\n\n\n\n\nCode\n# Matriz de confusión\nprint(\"Matriz de Confusión:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# Reporte de métricas\nprint(\"\\nReporte de Clasificación:\")\nprint(classification_report(y_test, y_pred))\n\n# AUC - ROC\nauc = roc_auc_score(y_test, y_prob)\nprint(f\"AUC: {auc:.3f}\")\n\n\nMatriz de Confusión:\n[[127  11]\n [ 17 145]]\n\nReporte de Clasificación:\n              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       138\n           1       0.93      0.90      0.91       162\n\n    accuracy                           0.91       300\n   macro avg       0.91      0.91      0.91       300\nweighted avg       0.91      0.91      0.91       300\n\nAUC: 0.975\n\n\n\n\n\n\n\nCode\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, label=f'AUC={auc:.2f}')\nplt.plot([0,1],[0,1],'--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Curva ROC\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=[\"Clase 0\",\"Clase 1\"],\n            yticklabels=[\"Clase 0\",\"Clase 1\"])\nplt.title(\"Matriz de Confusión\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n\n\n\n\n\n\n\nCode\ndata = load_breast_cancer()\n#data\nX = data.data #columnas\ny = data.target #filas\n\n\n\n\n\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(\n    X,y,test_size=0.2,random_state=42,stratify=y\n)\n\nprint(X_train)\nprint(X_test)\n\n\n[[1.032e+01 1.635e+01 6.531e+01 ... 2.381e-02 2.681e-01 7.399e-02]\n [2.018e+01 1.954e+01 1.338e+02 ... 2.173e-01 3.032e-01 8.075e-02]\n [1.066e+01 1.515e+01 6.749e+01 ... 0.000e+00 2.710e-01 6.164e-02]\n ...\n [1.546e+01 2.395e+01 1.038e+02 ... 2.163e-01 3.013e-01 1.067e-01]\n [1.705e+01 1.908e+01 1.134e+02 ... 2.543e-01 3.109e-01 9.061e-02]\n [1.088e+01 1.562e+01 7.041e+01 ... 7.966e-02 2.581e-01 1.080e-01]]\n[[1.955e+01 2.877e+01 1.336e+02 ... 1.941e-01 2.818e-01 1.005e-01]\n [1.113e+01 1.662e+01 7.047e+01 ... 4.044e-02 2.383e-01 7.083e-02]\n [1.382e+01 2.449e+01 9.233e+01 ... 1.521e-01 3.651e-01 1.183e-01]\n ...\n [1.532e+01 1.727e+01 1.032e+02 ... 2.229e-01 3.258e-01 1.191e-01]\n [1.262e+01 2.397e+01 8.135e+01 ... 1.180e-01 2.826e-01 9.585e-02]\n [1.168e+01 1.617e+01 7.549e+01 ... 9.815e-02 2.804e-01 8.024e-02]]\n\n\n\n\n\n\n\nCode\nmodel = LogisticRegression(max_iter=100000)\nmodel.fit(X_train,y_train)\n\n\nLogisticRegression(max_iter=100000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n100000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\n\n\nCode\ny_pred = model.predict(X_test)\n\n\n\n\n\n\n\nCode\naccurancy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall =recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"accurancy =\", accurancy)\nprint(\"precision =\",precision)\nprint(\"recall =\", recall)\nprint(\"f1 =\", f1)\n\n\naccurancy = 0.9649122807017544\nprecision = 0.9594594594594594\nrecall = 0.9861111111111112\nf1 = 0.9726027397260274"
  },
  {
    "objectID": "index.html#subtitulo-2",
    "href": "index.html#subtitulo-2",
    "title": "PRACTICAS",
    "section": "",
    "text": "Code\n%pip install matplotlib seaborn scikit-learn pandas numpy\n\n\nRequirement already satisfied: matplotlib in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (3.10.6)\nRequirement already satisfied: seaborn in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (1.7.2)\nRequirement already satisfied: pandas in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (2.3.2)\nRequirement already satisfied: numpy in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (2.2.6)\nRequirement already satisfied: contourpy&gt;=1.0.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler&gt;=0.10 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (4.60.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging&gt;=20.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow&gt;=8 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: python-dateutil&gt;=2.7 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy&gt;=1.8.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (1.16.2)\nRequirement already satisfied: joblib&gt;=1.2.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pytz&gt;=2020.1 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in f:\\2025\\mast_ia\\1.- fundamentos ia\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport seaborn as sns"
  },
  {
    "objectID": "index.html#generar-y-cargar-datos",
    "href": "index.html#generar-y-cargar-datos",
    "title": "PRACTICAS",
    "section": "",
    "text": "Code\nfrom sklearn.datasets import make_classification\n\n# Generar dataset ficticio\nX, y = make_classification(n_samples=1000, n_features=5, \n                           n_informative=3, n_redundant=0, \n                           random_state=42)\n\n# Dividir en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, \n                                                    random_state=42)\n\n\n\n\n\n\nCode\n# Crear el modelo\nmodelo = LogisticRegression()\n\n# Entrenar con los datos\nmodelo.fit(X_train, y_train)\n\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n100\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\n\n\nCode\n# Predicción de clases\ny_pred = modelo.predict(X_test)\n\n# Predicción de probabilidades\ny_prob = modelo.predict_proba(X_test)[:,1]  # prob. de clase positiva\n\n\n\n\n\n\n\nCode\n# Matriz de confusión\nprint(\"Matriz de Confusión:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# Reporte de métricas\nprint(\"\\nReporte de Clasificación:\")\nprint(classification_report(y_test, y_pred))\n\n# AUC - ROC\nauc = roc_auc_score(y_test, y_prob)\nprint(f\"AUC: {auc:.3f}\")\n\n\nMatriz de Confusión:\n[[127  11]\n [ 17 145]]\n\nReporte de Clasificación:\n              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       138\n           1       0.93      0.90      0.91       162\n\n    accuracy                           0.91       300\n   macro avg       0.91      0.91      0.91       300\nweighted avg       0.91      0.91      0.91       300\n\nAUC: 0.975\n\n\n\n\n\n\n\nCode\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, label=f'AUC={auc:.2f}')\nplt.plot([0,1],[0,1],'--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Curva ROC\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=[\"Clase 0\",\"Clase 1\"],\n            yticklabels=[\"Clase 0\",\"Clase 1\"])\nplt.title(\"Matriz de Confusión\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n\n\n\n\n\n\n\nCode\ndata = load_breast_cancer()\n#data\nX = data.data #columnas\ny = data.target #filas\n\n\n\n\n\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(\n    X,y,test_size=0.2,random_state=42,stratify=y\n)\n\nprint(X_train)\nprint(X_test)\n\n\n[[1.032e+01 1.635e+01 6.531e+01 ... 2.381e-02 2.681e-01 7.399e-02]\n [2.018e+01 1.954e+01 1.338e+02 ... 2.173e-01 3.032e-01 8.075e-02]\n [1.066e+01 1.515e+01 6.749e+01 ... 0.000e+00 2.710e-01 6.164e-02]\n ...\n [1.546e+01 2.395e+01 1.038e+02 ... 2.163e-01 3.013e-01 1.067e-01]\n [1.705e+01 1.908e+01 1.134e+02 ... 2.543e-01 3.109e-01 9.061e-02]\n [1.088e+01 1.562e+01 7.041e+01 ... 7.966e-02 2.581e-01 1.080e-01]]\n[[1.955e+01 2.877e+01 1.336e+02 ... 1.941e-01 2.818e-01 1.005e-01]\n [1.113e+01 1.662e+01 7.047e+01 ... 4.044e-02 2.383e-01 7.083e-02]\n [1.382e+01 2.449e+01 9.233e+01 ... 1.521e-01 3.651e-01 1.183e-01]\n ...\n [1.532e+01 1.727e+01 1.032e+02 ... 2.229e-01 3.258e-01 1.191e-01]\n [1.262e+01 2.397e+01 8.135e+01 ... 1.180e-01 2.826e-01 9.585e-02]\n [1.168e+01 1.617e+01 7.549e+01 ... 9.815e-02 2.804e-01 8.024e-02]]\n\n\n\n\n\n\n\nCode\nmodel = LogisticRegression(max_iter=100000)\nmodel.fit(X_train,y_train)\n\n\nLogisticRegression(max_iter=100000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n100000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\n\n\nCode\ny_pred = model.predict(X_test)\n\n\n\n\n\n\n\nCode\naccurancy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall =recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"accurancy =\", accurancy)\nprint(\"precision =\",precision)\nprint(\"recall =\", recall)\nprint(\"f1 =\", f1)\n\n\naccurancy = 0.9649122807017544\nprecision = 0.9594594594594594\nrecall = 0.9861111111111112\nf1 = 0.9726027397260274"
  }
]